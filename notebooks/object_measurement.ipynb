{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_object_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylehounslow/bmw_2019/blob/master/notebooks/object_measurement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjXDcAQjkXVi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Object Detection and 3D measurement from point cloud  \n",
        "___\n",
        "Topics covered in this notebook:  \n",
        "* Importing code from Github to work with Colab  \n",
        "* Object detection with YOLOv3  \n",
        "* Working with Depth images  \n",
        "* Combining object detection and point cloud data to localize objects in 3D space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bFFbN5godKE",
        "colab_type": "text"
      },
      "source": [
        "## Environment setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLDgxoh22Pqr",
        "colab_type": "text"
      },
      "source": [
        "### Make sure our runtime has a GPU attached usig `nvidia-smi` shell command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uspeHtUaKn1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkARyATJKDYd",
        "colab_type": "text"
      },
      "source": [
        "### clone the `bmw_2019` repository to our colab instance and install the required libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUkrHPO6JTjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf bmw_2019 && git clone --quiet https://github.com/kylehounslow/bmw_2019.git\n",
        "!pip install --quiet -r bmw_2019/requirements_colab.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PQV-UGhLf_R",
        "colab_type": "text"
      },
      "source": [
        "### Import the YOLOV3 module and some other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha2cvn9fpJsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import youtube_dl\n",
        "from google.colab.files import download\n",
        "from bmw_2019.models.keras_yolov3 import YOLOV3\n",
        "from bmw_2019 import util\n",
        "plt.style.use('default')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGdIChJFo4yX",
        "colab_type": "text"
      },
      "source": [
        "## Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJFVWzntkiMq",
        "colab_type": "text"
      },
      "source": [
        "### Instatiate the detector  \n",
        "The `__init__` function for `YOLOV3` will take care of downloading the pretrained model weights and setting up the necessary variables for inference.  \n",
        "See code [here](https://github.com/kylehounslow/bmw_2019/blob/master/models/keras_yolov3/src/yolo.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pclDZPz5qebA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detector = YOLOV3()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8XIJYCRKZFW",
        "colab_type": "text"
      },
      "source": [
        "### Render the YOLOV3 Model Architecture a notebook cell\n",
        "Note: You'll need to zoom in!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5_wHu_l30k3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython.display import  HTML\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = strip_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        if n.op == 'Const':\n",
        "            tensor = n.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = tf.compat.as_bytes(\"<stripped %d bytes>\"%size)\n",
        "    return strip_def\n",
        "  \n",
        "def rename_nodes(graph_def, rename_func):\n",
        "    res_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = res_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        n.name = rename_func(n.name)\n",
        "        for i, s in enumerate(n.input):\n",
        "            n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
        "    return res_def\n",
        "  \n",
        "def show_graph(graph_def, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "  \n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "    display(HTML(iframe))\n",
        "show_graph(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mdrNy06pB6M",
        "colab_type": "text"
      },
      "source": [
        "### Download image from URL and run detection\n",
        " The following defines a form widget for user input, downloads image and runs inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB_IRRv9MoE3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ## Detect objects from image url\n",
        "#@markdown ### Enter an image URL:\n",
        "url = \"https://i.ytimg.com/vi/gcI1BP1SlCk/maxresdefault.jpg\" #@param {type:\"string\"}\n",
        "img = util.download_image(url)\n",
        "plt.figure(figsize=(18,12))\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "detections = detector.detect(image=img)\n",
        "img_draw = detector.draw_detections(img, detections)\n",
        "plt.figure(figsize=(18,12))\n",
        "plt.title(\"Detections\")\n",
        "plt.imshow(img_draw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJUFY12MWNkx",
        "colab_type": "text"
      },
      "source": [
        "### Or we can capture image from client webcam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GcOXuGEWSOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import Image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture and Detect';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename\n",
        "\n",
        "try:\n",
        "    filename = take_photo()\n",
        "    img = Image.open(filename)\n",
        "    img = np.array(img)\n",
        "    detections = detector.detect(image=cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    img_draw = detector.draw_detections(img, detections)\n",
        "    plt.figure(figsize=(18,12))\n",
        "    plt.imshow(img_draw)\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "    print(str(err))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkZ6tv7Wklni",
        "colab_type": "text"
      },
      "source": [
        "### Or we can upload an image and run detection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_tOmd-5JaPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab import files\n",
        "def upload_detect_show(detector):\n",
        "    uploaded_files = files.upload()\n",
        "    image_filenames = list(uploaded_files.keys())\n",
        "    for image_filename in image_filenames:\n",
        "        image = Image.open(image_filename)\n",
        "        detections = detector.detect(image=image)\n",
        "        img_draw = detector.draw_detections(image, detections)\n",
        "        return Image.fromarray(img_draw)\n",
        "upload_detect_show(detector=detector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUkjREdvWSQc",
        "colab_type": "text"
      },
      "source": [
        "## Working with Depth data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AE9clynuxMz",
        "colab_type": "text"
      },
      "source": [
        "### Load RGBD image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGNxgxTKWYQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rgbd = cv2.imread('./bmw_2019/notebooks/data/rgbd1.png', cv2.IMREAD_UNCHANGED)  # NOTE: IMREAD_UNCHANGED loads image as its original uint16 dtype\n",
        "print(rgbd.shape, rgbd.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXuxdzrtoBe",
        "colab_type": "text"
      },
      "source": [
        "### Split the RGBD image into RGB + Depth\n",
        "Recall that numpy images are indexed by `[row, col, channel]`\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1000/1*Ikn1J6siiiCSk4ivYUhdgw.png\" style=\"height:50px; width:50px\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d76OG-BYttfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rgb = rgbd[:, :, :3]  # first 3 channels is RGB\n",
        "depth = rgbd[:, :, -1]  # last channel is depth\n",
        "\n",
        "print(rgb.shape, rgb.dtype, depth.shape, rgb.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOOEQsaQuhVA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"RGB Image\")\n",
        "plt.imshow(rgb)\n",
        "plt.show()\n",
        "plt.title(\"Depth Image\")\n",
        "plt.imshow(depth)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnJeWM_NupV2",
        "colab_type": "text"
      },
      "source": [
        "### Load Pointcloud data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuuUbfdBvIYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "point_cloud = np.load('./bmw_2019/notebooks/data/pc1.npy')\n",
        "print(point_cloud.shape, point_cloud.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gPbh7OrG17u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xyz = point_cloud.reshape(-1,3)\n",
        "print(xyz.shape, xyz.dtype)\n",
        "print(xyz[:10])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di5e9njKHGbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFqa8tweEsMe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xs = point_cloud[:, :, 0]\n",
        "ys = point_cloud[:, :, 1]\n",
        "h,w,c = point_cloud.shape\n",
        "(X, Y) = np.meshgrid(range(0, w, 10), range(0, h, 10), )\n",
        "plt.scatter(X, Y, point_cloud[Y, X])\n",
        "plt.scatter(point_cloud[Y, X], )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHmeE1TI20vI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cbook as cbook\n",
        "\n",
        "# Example image\n",
        "image_file = cbook.get_sample_data('grace_hopper.png')\n",
        "image = plt.imread(image_file)\n",
        "\n",
        "(r, c, b) = np.shape(image)\n",
        "\n",
        "# X and Y coordinates of points in the image, spaced by 10.\n",
        "(X, Y) = np.meshgrid(range(0, c, 10), range(0, r, 10), )\n",
        "\n",
        "# Display the image\n",
        "plt.imshow(image)\n",
        "# Plot points from the image.\n",
        "plt.scatter(X, Y, image[Y,X])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxdZPuXE3ES4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "image.shape"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}