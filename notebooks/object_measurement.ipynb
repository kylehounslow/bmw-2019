{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_object_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kylehounslow/bmw_2019/blob/master/notebooks/object_measurement.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjXDcAQjkXVi",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# Object Detection and 3D measurement from point cloud  \n",
        "___\n",
        "Topics covered in this notebook:  \n",
        "* Importing code from Github to work with Colab  \n",
        "* Object detection with YOLOv3  \n",
        "* Working with Point cloud data\n",
        "* Combining object detection and point clouds to localize objects in 3D space."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bFFbN5godKE",
        "colab_type": "text"
      },
      "source": [
        "## Environment setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLDgxoh22Pqr",
        "colab_type": "text"
      },
      "source": [
        "### Make sure our runtime has a GPU attached usig `nvidia-smi` shell command"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uspeHtUaKn1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkARyATJKDYd",
        "colab_type": "text"
      },
      "source": [
        "### clone the `bmw_2019` repository to our colab instance and install the required libraries\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OUkrHPO6JTjB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!rm -rf bmw_2019 && git clone --quiet https://github.com/kylehounslow/bmw_2019.git\n",
        "!pip install --quiet -r bmw_2019/requirements_colab.txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PQV-UGhLf_R",
        "colab_type": "text"
      },
      "source": [
        "### Import the YOLOV3 module and some other dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ha2cvn9fpJsS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.animation as animation\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import youtube_dl\n",
        "from google.colab.files import download\n",
        "from bmw_2019.models.keras_yolov3 import YOLOV3\n",
        "from bmw_2019 import util\n",
        "plt.style.use('default')\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGdIChJFo4yX",
        "colab_type": "text"
      },
      "source": [
        "## Section 1: Object Detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJFVWzntkiMq",
        "colab_type": "text"
      },
      "source": [
        "### Instatiate the detector  \n",
        "The `__init__` function for `YOLOV3` will take care of downloading the pretrained model weights and setting up the necessary variables for inference.  \n",
        "See yolov3 source code [here](https://github.com/kylehounslow/bmw_2019/blob/master/models/keras_yolov3/src/yolo.py)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pclDZPz5qebA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "detector = YOLOV3()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8XIJYCRKZFW",
        "colab_type": "text"
      },
      "source": [
        "### Render the YOLOV3 Model Architecture a notebook cell\n",
        "Note: You'll need to zoom in!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y5_wHu_l30k3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython.display import  HTML\n",
        "def strip_consts(graph_def, max_const_size=32):\n",
        "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
        "    strip_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = strip_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        if n.op == 'Const':\n",
        "            tensor = n.attr['value'].tensor\n",
        "            size = len(tensor.tensor_content)\n",
        "            if size > max_const_size:\n",
        "                tensor.tensor_content = tf.compat.as_bytes(\"<stripped %d bytes>\"%size)\n",
        "    return strip_def\n",
        "  \n",
        "def rename_nodes(graph_def, rename_func):\n",
        "    res_def = tf.GraphDef()\n",
        "    for n0 in graph_def.node:\n",
        "        n = res_def.node.add() \n",
        "        n.MergeFrom(n0)\n",
        "        n.name = rename_func(n.name)\n",
        "        for i, s in enumerate(n.input):\n",
        "            n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
        "    return res_def\n",
        "  \n",
        "def show_graph(graph_def, max_const_size=32):\n",
        "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
        "    if hasattr(graph_def, 'as_graph_def'):\n",
        "        graph_def = graph_def.as_graph_def()\n",
        "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
        "    code = \"\"\"\n",
        "        <script>\n",
        "          function load() {{\n",
        "            document.getElementById(\"{id}\").pbtxt = {data};\n",
        "          }}\n",
        "        </script>\n",
        "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
        "        <div style=\"height:600px\">\n",
        "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
        "        </div>\n",
        "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
        "  \n",
        "    iframe = \"\"\"\n",
        "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
        "    \"\"\".format(code.replace('\"', '&quot;'))\n",
        "    display(HTML(iframe))\n",
        "show_graph(tf.get_default_graph())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mdrNy06pB6M",
        "colab_type": "text"
      },
      "source": [
        "### Download image from URL and run detection\n",
        " The following defines a form widget for user input, downloads image and runs inference "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oB_IRRv9MoE3",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title ## Detect objects from image url\n",
        "#@markdown ### Enter an image URL:\n",
        "url = \"https://i.ytimg.com/vi/gcI1BP1SlCk/maxresdefault.jpg\" #@param {type:\"string\"}\n",
        "img = util.download_image(url)\n",
        "plt.figure(figsize=(18,12))\n",
        "plt.title(\"Original Image\")\n",
        "plt.imshow(img)\n",
        "plt.show()\n",
        "detections = detector.detect(image=img)\n",
        "img_draw = detector.draw_detections(img, detections)\n",
        "plt.figure(figsize=(18,12))\n",
        "plt.title(\"Detections\")\n",
        "plt.imshow(img_draw)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJUFY12MWNkx",
        "colab_type": "text"
      },
      "source": [
        "### Or we can capture image from client webcam"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8GcOXuGEWSOv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from IPython.display import display, Javascript\n",
        "from google.colab.output import eval_js\n",
        "from base64 import b64decode\n",
        "from IPython.display import Image\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def take_photo(filename='photo.jpg', quality=0.8):\n",
        "    js = Javascript('''\n",
        "    async function takePhoto(quality) {\n",
        "      const div = document.createElement('div');\n",
        "      const capture = document.createElement('button');\n",
        "      capture.textContent = 'Capture and Detect';\n",
        "      div.appendChild(capture);\n",
        "\n",
        "      const video = document.createElement('video');\n",
        "      video.style.display = 'block';\n",
        "      const stream = await navigator.mediaDevices.getUserMedia({video: true});\n",
        "\n",
        "      document.body.appendChild(div);\n",
        "      div.appendChild(video);\n",
        "      video.srcObject = stream;\n",
        "      await video.play();\n",
        "\n",
        "      // Resize the output to fit the video element.\n",
        "      google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);\n",
        "\n",
        "      // Wait for Capture to be clicked.\n",
        "      await new Promise((resolve) => capture.onclick = resolve);\n",
        "\n",
        "      const canvas = document.createElement('canvas');\n",
        "      canvas.width = video.videoWidth;\n",
        "      canvas.height = video.videoHeight;\n",
        "      canvas.getContext('2d').drawImage(video, 0, 0);\n",
        "      stream.getVideoTracks()[0].stop();\n",
        "      div.remove();\n",
        "      return canvas.toDataURL('image/jpeg', quality);\n",
        "    }\n",
        "    ''')\n",
        "    display(js)\n",
        "    data = eval_js('takePhoto({})'.format(quality))\n",
        "    binary = b64decode(data.split(',')[1])\n",
        "    with open(filename, 'wb') as f:\n",
        "        f.write(binary)\n",
        "    return filename\n",
        "\n",
        "try:\n",
        "    filename = take_photo()\n",
        "    img = Image.open(filename)\n",
        "    img = np.array(img)\n",
        "    detections = detector.detect(image=cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
        "    img_draw = detector.draw_detections(img, detections)\n",
        "    plt.figure(figsize=(12,8))\n",
        "    plt.imshow(img_draw)\n",
        "except Exception as err:\n",
        "  # Errors will be thrown if the user does not have a webcam or if they do not\n",
        "  # grant the page permission to access it.\n",
        "    print(str(err))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KkZ6tv7Wklni",
        "colab_type": "text"
      },
      "source": [
        "### Or we can upload an image and run detection "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_tOmd-5JaPT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from PIL import Image\n",
        "import cv2\n",
        "from google.colab import files\n",
        "def upload_detect_show(detector):\n",
        "    uploaded_files = files.upload()\n",
        "    image_filenames = list(uploaded_files.keys())\n",
        "    for image_filename in image_filenames:\n",
        "        image = Image.open(image_filename)\n",
        "        detections = detector.detect(image=image)\n",
        "        img_draw = detector.draw_detections(image, detections)\n",
        "        return Image.fromarray(img_draw)\n",
        "upload_detect_show(detector=detector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZUkjREdvWSQc",
        "colab_type": "text"
      },
      "source": [
        "## Section 2: Working with Depth data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5AE9clynuxMz",
        "colab_type": "text"
      },
      "source": [
        "### Load RGBD image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGNxgxTKWYQS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rgbd = cv2.imread('./bmw_2019/notebooks/data/rgbd.png', cv2.IMREAD_UNCHANGED)  # NOTE: IMREAD_UNCHANGED loads image as its original uint16 dtype\n",
        "print(rgbd.shape, rgbd.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fVXuxdzrtoBe",
        "colab_type": "text"
      },
      "source": [
        "### Exercise: Split the RGBD image into RGB + Depth and plot using `plt.imshow`\n",
        "Recall that numpy images are indexed by `[row, col, channel]`\n",
        "\n",
        "<img src=\"https://miro.medium.com/max/1000/1*Ikn1J6siiiCSk4ivYUhdgw.png\" style=\"height:50px; width:50px\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d76OG-BYttfV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rgb = \"your code goes here\"  # hint: first 3 channels is RGB\n",
        "depth = \"your code goes here\"  # hint: last channel is depth\n",
        "\n",
        "# print(rgb.shape, rgb.dtype, depth.shape, rgb.dtype)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBD3oeHXUlkN",
        "colab_type": "text"
      },
      "source": [
        "### Solution\n",
        "\n",
        "Click below for a solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "cellView": "both",
        "id": "eaK21Nb7VBNG",
        "colab": {}
      },
      "source": [
        "rgb = rgbd[:, :, :3]  # first 3 channels is RGB\n",
        "depth = rgbd[:, :, -1]  # last channel is depth\n",
        "\n",
        "print(rgb.shape, rgb.dtype, depth.shape, rgb.dtype)\n",
        "\n",
        "plt.title(\"RGB Image\")\n",
        "plt.imshow(rgb)\n",
        "plt.show()\n",
        "plt.title(\"Depth Image\")\n",
        "plt.imshow(depth)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YnJeWM_NupV2",
        "colab_type": "text"
      },
      "source": [
        "### Load Pointcloud data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuuUbfdBvIYQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "point_cloud = np.load('./bmw_2019/notebooks/data/point_cloud.npy')\n",
        "print(point_cloud.shape, point_cloud.dtype)\n",
        "print(point_cloud[:5])  # print first 5 elements"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gslGYXWccfGD",
        "colab_type": "text"
      },
      "source": [
        "### Subsample the point cloud and plot in 3d\n",
        "Note: The point cloud data is in left-hand coordinate system:  \n",
        "* **x-axis:** left/right   \n",
        "* **y-axis:** up/down  \n",
        "* **z-axis:** +/- depth  \n",
        "  \n",
        "<img src=\"https://docs.microsoft.com/en-us/windows/win32/direct3d9/images/leftrght.png\">\n",
        "  \n",
        "Matplotlib defaults to left-hand coord system with y/z axis swapped, so be sure to swap them when plotting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di5e9njKHGbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subsample_rate = 150\n",
        "x_subsample = point_cloud[:,0][1::subsample_rate]\n",
        "y_subsample = point_cloud[:,1][1::subsample_rate]\n",
        "z_subsample = point_cloud[:,2][1::subsample_rate]\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax3d = Axes3D(fig)\n",
        "ax3d.set_xlabel(\"x\")\n",
        "ax3d.set_ylabel(\"z\")\n",
        "ax3d.set_zlabel(\"y\")\n",
        "ax3d.set_xlim(x_subsample.min(), x_subsample.max())\n",
        "ax3d.set_ylim(z_subsample.min(), 2)  # only look 2 meters in z-direction\n",
        "ax3d.set_zlim(y_subsample.min(), y_subsample.max())\n",
        "ax3d.scatter(xs=x_subsample, ys=z_subsample, zs=y_subsample)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FED0e_33afO-",
        "colab_type": "text"
      },
      "source": [
        "### Looks a bit confusing from this angle. Rotate the plot about y-axis to look down -x axis (side view)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXZrz4cYanAZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"RGB Image reference\")\n",
        "plt.xlabel(\"x\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.imshow(rgb)\n",
        "plt.show()\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax3d = Axes3D(fig)\n",
        "ax3d.set_title(\"View along -x axis\")\n",
        "ax3d.set_xlabel(\"x\")\n",
        "ax3d.set_ylabel(\"z\")\n",
        "ax3d.set_zlabel(\"y\")\n",
        "ax3d.set_xlim(-1, 1)\n",
        "ax3d.set_ylim(z_subsample.min(), 2)\n",
        "ax3d.scatter(xs=x_subsample, ys=z_subsample, zs=y_subsample)\n",
        "ax3d.view_init(elev=0, azim=0) # rotate the axes to look down -x axis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vMgOM6hkbiw1",
        "colab_type": "text"
      },
      "source": [
        "### Rotate 90 degrees about x-axis to look down -y axis (top-down view) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdpOOvPKawEn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.title(\"RGB Image reference\")\n",
        "plt.imshow(rgb)\n",
        "plt.show()\n",
        "fig = plt.figure(figsize=(8, 8))\n",
        "ax3d = Axes3D(fig)\n",
        "ax3d.set_title(\"View along -y axis\")\n",
        "ax3d.set_xlabel(\"x\")\n",
        "ax3d.set_ylabel(\"z\")\n",
        "ax3d.set_zlabel(\"y\")\n",
        "ax3d.set_xlim(-1, 1)\n",
        "ax3d.set_ylim(z_subsample.min(), 2)\n",
        "ax3d.scatter(xs=x_subsample, ys=z_subsample, zs=y_subsample)\n",
        "# rotate the axes to look down -x axis\n",
        "ax3d.view_init(elev=90,  azim=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YS3dHZtIf9kP",
        "colab_type": "text"
      },
      "source": [
        "## Coding Challenge 1: Measure approximate distance to the glass bottle using the depth image\n",
        "Measured with a ruler the distance is about **~800mm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPjcXkntghOm",
        "colab_type": "text"
      },
      "source": [
        "### We'll start by locating the bottle in the RGB image using object detection\n",
        "This part is done for you. Simply execute cell below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QI81WVeEgevS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "img_rgb = rgb.astype(\"uint8\")  # CNN input must be unsigned 8-bit integer\n",
        "detections = detector.detect(img_rgb)\n",
        "for det in detections:\n",
        "    bbox = det.bbox\n",
        "    label = det.label\n",
        "    color = det.color\n",
        "    cv2.rectangle(img_rgb, (bbox[0], bbox[1]), (bbox[2], bbox[3]), color=color, thickness=5)\n",
        "    cv2.putText(img_rgb, str(label), (bbox[0], bbox[1]), 2, 2, color=color, thickness=5)\n",
        "plt.figure(figsize=(12,8))\n",
        "plt.imshow(img_rgb)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGQHph6Uieb2",
        "colab_type": "text"
      },
      "source": [
        "### Time to code! Find approximate distance to the bottle using the depth image\n",
        "Some information to help get started:  \n",
        "* The depth image contains unsigned 16-bit values rerpresenting the depth at each pixel coordinate in the image.  \n",
        "* The scale of the depth values are such that `1unit == 1mm`.\n",
        "* Each detection has a corresponding bounding box (`bbox`) and label. \n",
        "* bounding box coordinates are in `[x1, y1, x2, y2]` format or `[left, top, bottom, right]`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HyVdJGUUXrKI",
        "colab_type": "text"
      },
      "source": [
        "#### Crop the bottle in the depth image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kgGZFSmHl1dA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# iterate through detections and select the detection which has `bottle` label\n",
        "bottle = None\n",
        "\n",
        "# crop the depth image using bounding box coordinates\n",
        "depth_crop = \"your code goes here\"\n",
        "\n",
        "# plot the cropped depth image\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2x-HHSV1XAkO",
        "colab_type": "text"
      },
      "source": [
        "#### Solution\n",
        "\n",
        "Click below for a solution."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dB8TJ6XGWhFT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# select the detection which has `bottle` label\n",
        "bottle = None\n",
        "for det in detections:\n",
        "    if det.label == 'bottle':\n",
        "        bottle = det\n",
        "# crop the depth image using bounding box coordinates\n",
        "x1, y1, x2, y2 = bottle.bbox\n",
        "depth_crop = depth[y1:y2, x1:x2].copy()\n",
        "# plot the cropped depth image\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title(\"Cropped depth image\")\n",
        "plt.imshow(depth_crop)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9GX7nJLXvbl",
        "colab_type": "text"
      },
      "source": [
        "#### Plot the histogram of the depth image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC1L3sZ5tnF6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "depth_crop = depth_crop[np.nonzero(depth_crop)]  # first remove zero values from depth\n",
        "# plot the histogram and obtain the counts and values\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKHoG4htX8O9",
        "colab_type": "text"
      },
      "source": [
        "#### Solution\n",
        "click below for a solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "JbFdjlxMX6gP",
        "colab": {}
      },
      "source": [
        "depth_crop = depth_crop[np.nonzero(depth_crop)]  # first remove zero values from depth\n",
        "# plot the histogram and obtain the counts and values\n",
        "num_bins = 100\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.title(\"Depth image histogram\")\n",
        "counts, values, _ = plt.hist(depth_crop.flatten(), bins=num_bins)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MWdjsz2vZS1Q",
        "colab_type": "text"
      },
      "source": [
        "#### Filter the part of the histogram which is most likely to contain the bottle\n",
        "This part is a bit tricky. Of course you could manually enter values to filter, however we'd like to do this programmatically.   \n",
        "`hint: np.argmax(a) gives index of largest element in an array`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IBWEB2x4ZR_V",
        "colab": {}
      },
      "source": [
        "# your code goes here"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrcO204bYw9v",
        "colab_type": "text"
      },
      "source": [
        "#### Solution\n",
        "click below for a solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLN6Jm4oqx_P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window = 30  # a bit of a cheat but let's allow it\n",
        "peak_idx = np.argmax(counts)  # get index of largest counts\n",
        "peak_counts, peak_val = counts[peak_idx], values[peak_idx]  # get largest value\n",
        "depth_bottle = depth_crop.copy()\n",
        "depth_bottle[depth_bottle < peak_val - window] = 0  # filter on either side of the peak by a defined window\n",
        "depth_bottle[depth_bottle > peak_val + window] = 0\n",
        "depth_bottle = depth_bottle[np.nonzero(depth_bottle)]  # remove zero valued depth\n",
        "counts_2, values_2, _ = plt.hist(depth_bottle.flatten(), bins=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9YrDzjaY_04",
        "colab_type": "text"
      },
      "source": [
        "#### Calculate the approximate distance to the bottle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Sv7wTsJJY-Is",
        "colab": {}
      },
      "source": [
        "dist = -12345\n",
        "print(\"approimate distance is: {}mm\".format(round(dist)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E7Fo9ep9Y26I",
        "colab_type": "text"
      },
      "source": [
        "#### Solution\n",
        "click below for a solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlBo-g-ouCKe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist = np.mean(values_2)\n",
        "print(\"approimate distance is: {}mm\".format(round(dist)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6eREFpCvpvO",
        "colab_type": "text"
      },
      "source": [
        "## Coding Challenge 2: Measure height and width of glass bottle using the point cloud\n",
        "Measured with a ruler the dimensions are about **~65mm x 265mm**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lQLMh4ojchGS",
        "colab_type": "text"
      },
      "source": [
        "#### Reshape the point cloud to the same dimensions as rgb image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3DPbfjvxEiI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape the point cloud to same dimensions as rgb image\n",
        "pc_res = \"your code goes here\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aO6YSaOYcWiD",
        "colab_type": "text"
      },
      "source": [
        "#### Solution\n",
        "click below for a solution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ3dRCQswuyX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# crop the point cloud using detection bounding box\n",
        "pc_res_crop = pc_res[y1:y2, x1:x2, :].copy()\n",
        "print(pc_res_crop.shape)\n",
        "plt.imshow(pc_res_crop)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM3_Ul5JcGme",
        "colab_type": "text"
      },
      "source": [
        "#### Plot in 3D"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3EQIezzC4ch",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "points3d = pc_res_crop.reshape(-1, 3)\n",
        "xs = points3d[:,0]\n",
        "ys = points3d[:,1]\n",
        "zs = points3d[:,2]\n",
        "fig = plt.figure(figsize=plt.figaspect(5))\n",
        "# fig = plt.figure()\n",
        "ax3d = Axes3D(fig)\n",
        "ax3d.set_xlabel(\"x\")\n",
        "ax3d.set_ylabel(\"z\")\n",
        "ax3d.set_zlabel(\"y\")\n",
        "ax3d.set_xlim(xs.min(), xs.max())\n",
        "ax3d.set_ylim(zs.min(), zs.max())\n",
        "ax3d.set_zlim(ys.min(), ys.max())\n",
        "ax3d.scatter(xs=xs, ys=zs, zs=ys)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v7wI_2Cw40u_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(8,8))\n",
        "plt.title(\"Point cloud z values histogram\")\n",
        "z_vals = pc_res_crop[:,:,2].flatten()\n",
        "z_vals = z_vals[np.nonzero(z_vals)]  # remove zero values from depth\n",
        "counts_pc, values_pc, _ = plt.hist(z_vals, bins=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n1t4aORA6yKC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "window = 30*1e-3\n",
        "peak_idx_pc = np.argmax(counts_pc)\n",
        "peak_counts_pc, peak_val_pc = counts_pc[peak_idx_pc], values_pc[peak_idx_pc]\n",
        "points_bottle_pc = pc_res_crop.copy()\n",
        "points_bottle_pc[points_bottle_pc[:,:,2] < peak_val_pc - window] = 0  # filter z values only\n",
        "points_bottle_pc[points_bottle_pc[:,:,2] > peak_val_pc + window] = 0  # filter z values only\n",
        "nonzero_x, nonzero_y, nonzero_z = np.nonzero(points_bottle_pc)\n",
        "points_bottle_pc = points_bottle_pc[nonzero_x, nonzero_y, nonzero_z].reshape(-1, 3)  # remove zero valued z\n",
        "z_vals = points_bottle_pc[:, 2]\n",
        "counts_pc, values_pc, _ = plt.hist(z_vals, bins=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-h9teg2n8B8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dist_pc = np.mean(values_pc)\n",
        "print(\"approimate distance is: {}mm\".format(round(dist_pc*1e3)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxTh-WQU3v3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "xs = points_bottle_pc[:,0]\n",
        "ys = points_bottle_pc[:,1]\n",
        "zs = points_bottle_pc[:,2]\n",
        "fig = plt.figure(figsize=plt.figaspect(5))\n",
        "ax3d = Axes3D(fig)\n",
        "ax3d.set_title(\"Bottle Front View\")\n",
        "ax3d.set_xlabel(\"x\")\n",
        "ax3d.set_ylabel(\"z\")\n",
        "ax3d.set_zlabel(\"y\")\n",
        "ax3d.set_xlim(xs.min(), xs.max())\n",
        "ax3d.set_ylim(zs.min(), zs.max())\n",
        "ax3d.set_zlim(ys.min(), ys.max())\n",
        "ax3d.scatter(xs=xs, ys=zs, zs=ys)\n",
        "ax3d.view_init(elev=0, azim=90)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gg7xtvIhQbgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%HTML\n",
        "<div align=\"middle\">\n",
        "<video width=\"80%\" controls>\n",
        "      <source src=\"./animation.mp4\" type=\"video/mp4\">\n",
        "</video></div>"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1HXmLZb4pag",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = points_bottle_pc[:,0]\n",
        "y = points_bottle_pc[:,1]\n",
        "z = points_bottle_pc[:,2]\n",
        "width = abs(x.max() - x.min())*1e3\n",
        "height = abs(y.max() - y.min())*1e3\n",
        "print(\"approximate dimensions are {}mm x {}mm\".format(int(width), int(height)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}